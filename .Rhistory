plot(x=Ns, y=test_sizes, type="l", col="orange",
xlab="available population (N)", ylab="profit-maximizing sample size")
mus <- (1:1000)/100
test_sizes <- rep(NA, length(mus))
for (i in 1:length(mus))
test_sizes[i] <- test_size_nn(N=N, s=s, mu=mus[i], sigma=sigma)[1]
plot(x=mus, y=test_sizes,
type="l", col="orange",
xlab="expected average profit per customer (mu)", ylab="profit-maximizing sample size")
ss <- (1:1000)/1000
test_sizes <- rep(NA, length(ss))
for (i in 1:length(ss))
test_sizes[i] <- test_size_nn(N=N, s=ss[i], mu=mu, sigma=sigma)[1]
plot(x=ss, y=test_sizes, type="l", col="orange",
xlab="noise in profit per customer (s)", ylab="profit-maximizing sample size")
plot_prior_effect_nn(mu, sigma, abs=TRUE)
plot(x=sigma, y=test_sizes, type="l", col="orange",
xlab="prior sd of treatment mean profit (sigma)", ylab="profit-maximizing sample size")
plot(x=sigmas, y=test_sizes, type="l", col="orange",
xlab="prior sd of treatment mean profit (sigma)", ylab="profit-maximizing sample size")
generate_syn_expt <- function(nexpt, nobs, mu, sigma, omega) {
nobs <- matrix(nobs, nrow=nexpt, ncol=2) # equal test sizes
y <- matrix(NA, nrow=nexpt, ncol=2)
for (e in 1:nexpt) {
t <- rnorm(1, mean=mu, sd=omega)
m <- rnorm(2, mean=t, sd=sigma)
while (min(t,m) < 0 | max(t,m) > 1) { # reject values outside [0,1]
t <- rnorm(1, mean=mu, sd=omega)
m <- rnorm(2, mean=t, sd=sigma)
}
y[e, 1] <- mean(rnorm(nobs[e,1], mean=m[1], sd=sqrt(m[1]*(1-m[1]))))
y[e, 2] <- mean(rnorm(nobs[e,2], mean=m[2], sd=sqrt(m[2]*(1-m[2]))))
}
list(nexpt=nexpt, y=y, nobs=nobs)
}
set.seed(19980103)
expts <- generate_syn_expt(nexpt=100, nobs=100000,
mu=0.676, sigma=0.030, omega=0.199) # pop estimates from paper
summary(expts$y)
summary(expts$y)
generate_syn_expt <- function(nexpt, nobs, mu, sigma, omega) {
nobs <- matrix(nobs, nrow=nexpt, ncol=2) # equal test sizes
y <- matrix(NA, nrow=nexpt, ncol=2)
for (e in 1:nexpt) {
t <- rnorm(1, mean=mu, sd=omega)
m <- rnorm(2, mean=t, sd=sigma)
while (min(t,m) < 0 | max(t,m) > 1) { # reject values outside [0,1]
t <- rnorm(1, mean=mu, sd=omega)
m <- rnorm(2, mean=t, sd=sigma)
}
y[e, 1] <- mean(rnorm(nobs[e,1], mean=m[1], sd=sqrt(m[1]*(1-m[1]))))
y[e, 2] <- mean(rnorm(nobs[e,2], mean=m[2], sd=sqrt(m[2]*(1-m[2]))))
}
names(y) <- c("ave_conv_A", "ave_conv_B")
list(nexpt=nexpt, y=y, nobs=nobs)
}
set.seed(19980103)
expts <- generate_syn_expt(nexpt=100, nobs=100000,
mu=0.676, sigma=0.030, omega=0.199) # pop estimates from paper
summary(expts$y)
library(rstan)
library(dplyr)
# Simulate data
set.seed(19104)
group <- c(rep("A", 500), rep("B", 500))
time_on_site <- c(rnorm(500, mean=5.2, sd=2), rnorm(500, mean=5.4, sd=2.2))
test_data <- data.frame(group, time_on_site)
rm(group, time_on_site)
test_data %>%
group_by(group) %>% summarize(mean=mean(time_on_site), sd=sd(time_on_site), n=n())
plot(x=-300:300, y=dnorm(-300:300, mean=0, sd=100),
type="l", col="gray", xlab="mean time-on-site (m)", ylab="prior density")
n_A <- sum(test_data$group=="A")
n_B <- sum(test_data$group=="B")
s <- sd(test_data$time_on_site)
post_mean_A <- mean(test_data[test_data$group=="A", "time_on_site"])
post_mean_B <- mean(test_data[test_data$group=="B", "time_on_site"])
post_sd_A <- (1/100^2 + n_A/s^2)^-(1/2)
post_sd_B <- (1/100^2 + n_B/s^2)^-(1/2)
plot(x=(450:600)/100, y=dnorm((450:600)/100, mean=post_mean_A, sd=post_sd_A),
type="l", col="blue", xlab="mean time-on-site (m)", ylab="posterior density")
lines(x=(450:600)/100, y=dnorm((450:600)/100, mean=post_mean_B, sd=post_sd_B), col="red")
lines(x=(450:600)/100, y=dnorm((450:600)/100, mean=0, sd=100), col="gray")
legend("topright", col=c("blue", "red", "gray"), legend=c("posterior for A", "posterior for B", "prior"), bty="n", lty=1)
qnorm(c(0.025, 0.975), mean=post_mean_A, sd=post_sd_A) # CI for A
qnorm(c(0.025, 0.975), mean=post_mean_B, sd=post_sd_B) # CI for B
post_mean_diff <- post_mean_B - post_mean_A
post_sd_diff <- sqrt(post_sd_B^2 + post_sd_A^2)
plot(x=(-50:60)/100, y=dnorm((-50:60)/100, mean=post_mean_diff, sd=post_sd_diff),
type="l", col="black",
xlab="difference in mean time-on-site (m)", ylab="posterior density")
abline(v=0)
text(-0.25, 2.9, "A has higher mean time-on-site")
text(0.35, 2.9, "B has higher mean time-on-site")
1-pnorm(0, mean=post_mean_diff, sd=post_sd_diff)
plot(x=(450:600)/100, y=dnorm((450:600)/100, mean=post_mean_A, sd=post_sd_A),
type="l", col="blue", xlab="mean time-on-site (m)", ylab="posterior density")
lines(x=(450:600)/100, y=dnorm((450:600)/100, mean=post_mean_B, sd=post_sd_B), col="red")
lines(x=(450:600)/100, y=dnorm((450:600)/100, mean=0, sd=100), col="gray")
legend("topright", col=c("blue", "red", "gray"), legend=c("A", "B", "prior"), bty="n", lty=1)
source("nn_functions.R") #
N=100000 # available population
mu = 0.68  # average conversion rate across previous treatments
sigma = 0.03 # range of expected conversation rates across previous treatments
s = mu*(1-mu) # binomial approximation
test_size_nn(N=N, s=s, mu=mu, sigma=sigma) # compute the optimal test size
# Optimal test size
n_star <- test_size_nn(N=N, s=s, mu=mu, sigma=sigma)
test_eval_nn(n=n_star, N=N, s=s, mu=mu, sigma=sigma)
# A bigger test
test_eval_nn(n=c(10000, 10000), N=N, s=s, mu=mu, sigma=sigma)
# A smaller test
test_eval_nn(n=c(100, 100), N=N, s=s, mu=mu, sigma=sigma)
# NHT for comparison
d <- 0.68*0.02 # 2% lift
n_nht <- test_size_nht(s=sqrt(mu*(1-mu)), d=d) # to match the profit maximizing
eval_nht <- test_eval_nn(n=rep(n_nht, 2), N=N, s=sqrt(mu*(1-mu)), mu=mu, sigma=sigma)
# Plot
n <- c(1:19, 2:19*10, 2:19*100, 2:19*1000, 2:5*10000)
out <- NULL
for (i in 1:length(n)) {
out <- rbind(out, test_eval_nn(n=c(n[i], n[i]), N=N, s=sqrt(mu*(1-mu)), mu=mu, sigma=sigma))
}
plot(out$n1, out$profit, type="l",
ylim=c(out$profit_rand[1], out$profit_perfect[1]),
xlab=expression("Test Size (n"[1]*"=n"[2]*")"), ylab="Expected Profit")
abline(v=n_star)
text(n_star, 0.696*N, "n*=2,284", pos=4)
abline(v=n_nht, col="gray", lty=3)
text(n_nht, 0.683*N, expression(n[HT]), col="gray", pos=4)  # hard code
plot(out$n1, out$error_rate, type="l", ylim=c(0, 0.5),
xlab=expression("Test Size (n"[1]*"=n"[2]*")"), ylab="Error Rate")
abline(v=n_star)
text(n_star, 0.13, "n*=2,284", pos=4)
abline(v=n_nht, col="gray", lty=3)
text(n_nht, 0.3, expression(n[HT]), col="gray", pos=4)
Ns <- (1:1000)*1000
test_sizes <- rep(NA, length(Ns))
for (i in 1:length(Ns))
test_sizes[i] <- test_size_nn(N=Ns[i], s=s, mu=mu, sigma=sigma)[1]
plot(x=Ns, y=test_sizes, type="l", col="orange",
xlab="available population (N)", ylab="profit-maximizing sample size")
mus <- (1:1000)/100
test_sizes <- rep(NA, length(mus))
for (i in 1:length(mus))
test_sizes[i] <- test_size_nn(N=N, s=s, mu=mus[i], sigma=sigma)[1]
plot(x=mus, y=test_sizes,
type="l", col="orange",
xlab="expected average profit per customer (mu)", ylab="profit-maximizing sample size")
ss <- (1:1000)/1000
test_sizes <- rep(NA, length(ss))
for (i in 1:length(ss))
test_sizes[i] <- test_size_nn(N=N, s=ss[i], mu=mu, sigma=sigma)[1]
plot(x=ss, y=test_sizes, type="l", col="orange",
xlab="noise in profit per customer (s)", ylab="profit-maximizing sample size")
plot_prior_effect_nn(mu, sigma, abs=TRUE)
sigmas <- (1:1000)/10000
test_sizes <- rep(NA, length(sigmas))
for (i in 1:length(sigmas))
test_sizes[i] <- test_size_nn(N=N, s=s, mu=mu, sigma=sigmas[i])[1]
plot(x=sigmas, y=test_sizes, type="l", col="orange",
xlab="prior sd of treatment mean profit (sigma)", ylab="profit-maximizing sample size")
generate_syn_expt <- function(nexpt, nobs, mu, sigma, omega) {
nobs <- matrix(nobs, nrow=nexpt, ncol=2) # equal test sizes
y <- matrix(NA, nrow=nexpt, ncol=2)
for (e in 1:nexpt) {
t <- rnorm(1, mean=mu, sd=omega)
m <- rnorm(2, mean=t, sd=sigma)
while (min(t,m) < 0 | max(t,m) > 1) { # reject values outside [0,1]
t <- rnorm(1, mean=mu, sd=omega)
m <- rnorm(2, mean=t, sd=sigma)
}
y[e, 1] <- mean(rnorm(nobs[e,1], mean=m[1], sd=sqrt(m[1]*(1-m[1]))))
y[e, 2] <- mean(rnorm(nobs[e,2], mean=m[2], sd=sqrt(m[2]*(1-m[2]))))
}
names(y) <- c("ave_conv_A", "ave_conv_B")
list(nexpt=nexpt, y=y, nobs=nobs)
}
set.seed(19980103)
expts <- generate_syn_expt(nexpt=100, nobs=100000,
mu=0.676, sigma=0.030, omega=0.199) # pop estimates from paper
names(expts$y)
summary(expts$y)
generate_syn_expt <- function(nexpt, nobs, mu, sigma, omega) {
nobs <- matrix(nobs, nrow=nexpt, ncol=2) # equal test sizes
y <- matrix(NA, nrow=nexpt, ncol=2)
for (e in 1:nexpt) {
t <- rnorm(1, mean=mu, sd=omega)
m <- rnorm(2, mean=t, sd=sigma)
while (min(t,m) < 0 | max(t,m) > 1) { # reject values outside [0,1]
t <- rnorm(1, mean=mu, sd=omega)
m <- rnorm(2, mean=t, sd=sigma)
}
y[e, 1] <- mean(rnorm(nobs[e,1], mean=m[1], sd=sqrt(m[1]*(1-m[1]))))
y[e, 2] <- mean(rnorm(nobs[e,2], mean=m[2], sd=sqrt(m[2]*(1-m[2]))))
}
names(y)[[2]] <- c("ave_conv_A", "ave_conv_B")
list(nexpt=nexpt, y=y, nobs=nobs)
}
set.seed(19980103)
expts <- generate_syn_expt(nexpt=100, nobs=100000,
mu=0.676, sigma=0.030, omega=0.199) # pop estimates from paper
names(expts$y)
summary(expts$y)
names(expts$y)
str(names(expts$y))
library(rstan)
library(dplyr)
# Simulate data
set.seed(19104)
group <- c(rep("A", 500), rep("B", 500))
time_on_site <- c(rnorm(500, mean=5.2, sd=2), rnorm(500, mean=5.4, sd=2.2))
test_data <- data.frame(group, time_on_site)
rm(group, time_on_site)
test_data %>%
group_by(group) %>% summarize(mean=mean(time_on_site), sd=sd(time_on_site), n=n())
plot(x=-300:300, y=dnorm(-300:300, mean=0, sd=100),
type="l", col="gray", xlab="mean time-on-site (m)", ylab="prior density")
n_A <- sum(test_data$group=="A")
n_B <- sum(test_data$group=="B")
s <- sd(test_data$time_on_site)
post_mean_A <- mean(test_data[test_data$group=="A", "time_on_site"])
post_mean_B <- mean(test_data[test_data$group=="B", "time_on_site"])
post_sd_A <- (1/100^2 + n_A/s^2)^-(1/2)
post_sd_B <- (1/100^2 + n_B/s^2)^-(1/2)
plot(x=(450:600)/100, y=dnorm((450:600)/100, mean=post_mean_A, sd=post_sd_A),
type="l", col="blue", xlab="mean time-on-site (m)", ylab="posterior density")
lines(x=(450:600)/100, y=dnorm((450:600)/100, mean=post_mean_B, sd=post_sd_B), col="red")
lines(x=(450:600)/100, y=dnorm((450:600)/100, mean=0, sd=100), col="gray")
legend("topright", col=c("blue", "red", "gray"), legend=c("posterior for A", "posterior for B", "prior"), bty="n", lty=1)
qnorm(c(0.025, 0.975), mean=post_mean_A, sd=post_sd_A) # CI for A
qnorm(c(0.025, 0.975), mean=post_mean_B, sd=post_sd_B) # CI for B
post_mean_diff <- post_mean_B - post_mean_A
post_sd_diff <- sqrt(post_sd_B^2 + post_sd_A^2)
plot(x=(-50:60)/100, y=dnorm((-50:60)/100, mean=post_mean_diff, sd=post_sd_diff),
type="l", col="black",
xlab="difference in mean time-on-site (m)", ylab="posterior density")
abline(v=0)
text(-0.25, 2.9, "A has higher mean time-on-site")
text(0.35, 2.9, "B has higher mean time-on-site")
1-pnorm(0, mean=post_mean_diff, sd=post_sd_diff)
plot(x=(450:600)/100, y=dnorm((450:600)/100, mean=post_mean_A, sd=post_sd_A),
type="l", col="blue", xlab="mean time-on-site (m)", ylab="posterior density")
lines(x=(450:600)/100, y=dnorm((450:600)/100, mean=post_mean_B, sd=post_sd_B), col="red")
lines(x=(450:600)/100, y=dnorm((450:600)/100, mean=0, sd=100), col="gray")
legend("topright", col=c("blue", "red", "gray"), legend=c("A", "B", "prior"), bty="n", lty=1)
source("nn_functions.R") #
N=100000 # available population
mu = 0.68  # average conversion rate across previous treatments
sigma = 0.03 # range of expected conversation rates across previous treatments
s = mu*(1-mu) # binomial approximation
test_size_nn(N=N, s=s, mu=mu, sigma=sigma) # compute the optimal test size
# Optimal test size
n_star <- test_size_nn(N=N, s=s, mu=mu, sigma=sigma)
test_eval_nn(n=n_star, N=N, s=s, mu=mu, sigma=sigma)
# A bigger test
test_eval_nn(n=c(10000, 10000), N=N, s=s, mu=mu, sigma=sigma)
# A smaller test
test_eval_nn(n=c(100, 100), N=N, s=s, mu=mu, sigma=sigma)
# NHT for comparison
d <- 0.68*0.02 # 2% lift
n_nht <- test_size_nht(s=sqrt(mu*(1-mu)), d=d) # to match the profit maximizing
eval_nht <- test_eval_nn(n=rep(n_nht, 2), N=N, s=sqrt(mu*(1-mu)), mu=mu, sigma=sigma)
# Plot
n <- c(1:19, 2:19*10, 2:19*100, 2:19*1000, 2:5*10000)
out <- NULL
for (i in 1:length(n)) {
out <- rbind(out, test_eval_nn(n=c(n[i], n[i]), N=N, s=sqrt(mu*(1-mu)), mu=mu, sigma=sigma))
}
plot(out$n1, out$profit, type="l",
ylim=c(out$profit_rand[1], out$profit_perfect[1]),
xlab=expression("Test Size (n"[1]*"=n"[2]*")"), ylab="Expected Profit")
abline(v=n_star)
text(n_star, 0.696*N, "n*=2,284", pos=4)
abline(v=n_nht, col="gray", lty=3)
text(n_nht, 0.683*N, expression(n[HT]), col="gray", pos=4)  # hard code
plot(out$n1, out$error_rate, type="l", ylim=c(0, 0.5),
xlab=expression("Test Size (n"[1]*"=n"[2]*")"), ylab="Error Rate")
abline(v=n_star)
text(n_star, 0.13, "n*=2,284", pos=4)
abline(v=n_nht, col="gray", lty=3)
text(n_nht, 0.3, expression(n[HT]), col="gray", pos=4)
Ns <- (1:1000)*1000
test_sizes <- rep(NA, length(Ns))
for (i in 1:length(Ns))
test_sizes[i] <- test_size_nn(N=Ns[i], s=s, mu=mu, sigma=sigma)[1]
plot(x=Ns, y=test_sizes, type="l", col="orange",
xlab="available population (N)", ylab="profit-maximizing sample size")
mus <- (1:1000)/100
test_sizes <- rep(NA, length(mus))
for (i in 1:length(mus))
test_sizes[i] <- test_size_nn(N=N, s=s, mu=mus[i], sigma=sigma)[1]
plot(x=mus, y=test_sizes,
type="l", col="orange",
xlab="expected average profit per customer (mu)", ylab="profit-maximizing sample size")
ss <- (1:1000)/1000
test_sizes <- rep(NA, length(ss))
for (i in 1:length(ss))
test_sizes[i] <- test_size_nn(N=N, s=ss[i], mu=mu, sigma=sigma)[1]
plot(x=ss, y=test_sizes, type="l", col="orange",
xlab="noise in profit per customer (s)", ylab="profit-maximizing sample size")
plot_prior_effect_nn(mu, sigma, abs=TRUE)
sigmas <- (1:1000)/10000
test_sizes <- rep(NA, length(sigmas))
for (i in 1:length(sigmas))
test_sizes[i] <- test_size_nn(N=N, s=s, mu=mu, sigma=sigmas[i])[1]
plot(x=sigmas, y=test_sizes, type="l", col="orange",
xlab="prior sd of treatment mean profit (sigma)", ylab="profit-maximizing sample size")
generate_syn_expt <- function(nexpt, nobs, mu, sigma, omega) {
nobs <- matrix(nobs, nrow=nexpt, ncol=2) # equal test sizes
y <- matrix(NA, nrow=nexpt, ncol=2)
for (e in 1:nexpt) {
t <- rnorm(1, mean=mu, sd=omega)
m <- rnorm(2, mean=t, sd=sigma)
while (min(t,m) < 0 | max(t,m) > 1) { # reject values outside [0,1]
t <- rnorm(1, mean=mu, sd=omega)
m <- rnorm(2, mean=t, sd=sigma)
}
y[e, 1] <- mean(rnorm(nobs[e,1], mean=m[1], sd=sqrt(m[1]*(1-m[1]))))
y[e, 2] <- mean(rnorm(nobs[e,2], mean=m[2], sd=sqrt(m[2]*(1-m[2]))))
}
colnames(y) <- c("A_conv_rate", "B_conv_rate")
list(nexpt=nexpt, y=y, nobs=nobs)
}
set.seed(19980103)
expts <- generate_syn_expt(nexpt=100, nobs=100000,
mu=0.676, sigma=0.030, omega=0.199) # pop estimates from paper
head(expts$y)
m1 <- sampling(stan_model, data=expts, seed=20030601, iter=1000)
library(rstan)
library(dplyr)
options(mc.cores = parallel::detectCores())
source("nn_functions.R")
summary(m1)$summary[,c(1,3,5,8)]
summary(m1, pars=c("omega", "sigma", "mu"))$summary[,c(1,3,5,8)]
(n_star <- test_size_nn(N=100000, mu=0.68, sigma=0.026, s=0.68*(1-0.68)))
test_eval_nn(n_star, )
(n_star <- test_size_nn(N=100000, mu=0.68, sigma=0.026, s=0.68*(1-0.68)))
test_eval_nn(n_star, N=100000, mu=0.68, sigma=0.026, s=0.68*(1-0.68)))
(n_star <- test_size_nn(N=100000, mu=0.68, sigma=0.026, s=0.68*(1-0.68)))
test_eval_nn(n_star, N=100000, mu=0.68, sigma=0.026, s=0.68*(1-0.68))
(n_star <- test_size_nn(N=100000, mu=0.68, sigma=0.026, s=0.68*(1-0.68)))
test_eval_nn(n_star, N=100000, mu=0.68, sigma=0.026, s=0.68*(1-0.68))
# simulate data
set.seed(19348)
group <- c(rep("A", 1272), rep("B", 1272))
profit <- c(rnorm(500, mean=0.5, sd=0.5*(1-0.5)),
rnorm(500, mean=0.55, sd=0.53*(1-0.53)))
test_data <- data.frame(group, profit)
# simulate data
set.seed(19348)
group <- c(rep("A", 1272), rep("B", 1272))
profit <- c(rnorm(1272, mean=0.5, sd=0.5*(1-0.5)),
rnorm(1272, mean=0.55, sd=0.53*(1-0.53)))
test_data <- data.frame(group, profit)
rm(group, profit)
summary(test_data)
summary(test_data)
test_data %>%
group_by(group) %>% summarize(mean=mean(time_on_site), sd=sd(time_on_site), n=n())
test_data %>%
group_by(group) %>% summarize(mean=mean(profit), sd=sd(profit), n=n())
# simulate data
set.seed(19348)
group <- c(rep("A", 1272), rep("B", 1272))
profit <- c(rnorm(1272, mean=0.53, sd=0.5*(1-0.5)),
rnorm(1272, mean=0.50, sd=0.53*(1-0.53)))
test_data <- data.frame(group, profit)
rm(group, profit)
test_data %>%
group_by(group) %>% summarize(mean=mean(profit), sd=sd(profit), n=n())
# simulate data
set.seed(19348)
group <- c(rep("A", 1272), rep("B", 1272))
profit <- c(rnorm(1272, mean=0.51, sd=0.5*(1-0.5)),
rnorm(1272, mean=0.50, sd=0.53*(1-0.53)))
test_data <- data.frame(group, profit)
rm(group, profit)
test_data %>%
group_by(group) %>% summarize(mean=mean(profit), sd=sd(profit), n=n())
n_A <- sum(test_data$group=="A")
n_B <- sum(test_data$group=="B")
s <- sd(test_data$time_on_site)
post_mean_A <- mean(test_data[test_data$group=="A", "time_on_site"])
post_mean_B <- mean(test_data[test_data$group=="B", "time_on_site"])
post_sd_A <- (1/100^2 + n_A/s^2)^-(1/2)
post_sd_B <- (1/100^2 + n_B/s^2)^-(1/2)
n_A <- sum(test_data$group=="A")
n_B <- sum(test_data$group=="B")
s <- sd(test_data$time_on_site)
post_mean_A <- mean(test_data[test_data$group=="A", "time_on_site"])
post_mean_B <- mean(test_data[test_data$group=="B", "time_on_site"])
post_sd_A <- (1/100^2 + n_A/s^2)^-(1/2)
post_sd_B <- (1/100^2 + n_B/s^2)^-(1/2)
plot(x=(450:600)/100, y=dnorm((450:600)/100, mean=post_mean_A, sd=post_sd_A),
type="l", col="blue", xlab="mean profit", ylab="posterior density")
n_A <- sum(test_data$group=="A")
n_B <- sum(test_data$group=="B")
s <- sd(test_data$time_on_site)
post_mean_A <- mean(test_data[test_data$group=="A", "time_on_site"])
post_mean_B <- mean(test_data[test_data$group=="B", "time_on_site"])
post_sd_A <- (1/100^2 + n_A/s^2)^-(1/2)
post_sd_B <- (1/100^2 + n_B/s^2)^-(1/2)
plot(x=(0:100)/100, y=dnorm((0:100)/100, mean=post_mean_A, sd=post_sd_A),
type="l", col="blue", xlab="mean profit", ylab="posterior density")
plot(x=(0:100)/100, y=dnorm((0:100)/100, mean=post_mean_A, sd=post_sd_A),
type="l", col="blue", xlab="mean profit", ylab="posterior density")
n_A <- sum(test_data$group=="A")
n_B <- sum(test_data$group=="B")
s <- sd(test_data$time_on_site)
post_mean_A <- mean(test_data[test_data$group=="A", "time_on_site"])
post_mean_B <- mean(test_data[test_data$group=="B", "time_on_site"])
post_sd_A <- (1/100^2 + n_A/s^2)^-(1/2)
post_sd_B <- (1/100^2 + n_B/s^2)^-(1/2)
n_A <- sum(test_data$group=="A")
n_B <- sum(test_data$group=="B")
s <- sd(test_data$time_on_site)
post_mean_A <- mean(test_data[test_data$group=="A", "profit"])
post_mean_B <- mean(test_data[test_data$group=="B", "profit"])
post_sd_A <- (1/100^2 + n_A/s^2)^-(1/2)
post_sd_B <- (1/100^2 + n_B/s^2)^-(1/2)
plot(x=(0:100)/100, y=dnorm((0:100)/100, mean=post_mean_A, sd=post_sd_A),
type="l", col="blue", xlab="mean profit", ylab="posterior density")
post_mean_A
post_mean_B
dnorm((0:100)/100, mean=post_mean_A, sd=post_sd_A)
n_A <- sum(test_data$group=="A")
n_B <- sum(test_data$group=="B")
s <- sd(test_data$time_on_site)
post_mean_A <- mean(test_data[test_data$group=="A", "profit"])
post_mean_B <- mean(test_data[test_data$group=="B", "profit"])
post_sd_A <- (1/100^2 + n_A/s^2)^-(1/2)
post_sd_B <- (1/100^2 + n_B/s^2)^-(1/2)
post_mean_A
post_sd_A
s
n_A <- sum(test_data$group=="A")
n_B <- sum(test_data$group=="B")
s <- sd(test_data$profit)
post_mean_A <- mean(test_data[test_data$group=="A", "profit"])
post_mean_B <- mean(test_data[test_data$group=="B", "profit"])
post_sd_A <- (1/100^2 + n_A/s^2)^-(1/2)
post_sd_B <- (1/100^2 + n_B/s^2)^-(1/2)
plot(x=(0:100)/100, y=dnorm((0:100)/100, mean=post_mean_A, sd=post_sd_A),
type="l", col="blue", xlab="mean profit", ylab="posterior density")
lines(x=(0:100)/100, y=dnorm((0:100)/100, mean=post_mean_B, sd=post_sd_B), col="red")
lines(x=(0:100)/100, y=dnorm((0:100)/100, mean=0, sd=100), col="gray")
legend("topright", col=c("blue", "red", "gray"), legend=c("posterior for A", "posterior for B", "prior"), bty="n", lty=1)
plot(x=(0:100)/100, y=dnorm((0:100)/100, mean=post_mean_A, sd=post_sd_A),
type="l", col="blue", xlab="mean profit", ylab="posterior density")
lines(x=(400:600)/100, y=dnorm((400:600)/100, mean=post_mean_B, sd=post_sd_B), col="red")
lines(x=(400:600)/100, y=dnorm((400:600)/100, mean=0, sd=100), col="gray")
legend("topright", col=c("blue", "red", "gray"), legend=c("posterior for A", "posterior for B", "prior"), bty="n", lty=1)
plot(x=(400:600)/100, y=dnorm((400:600)/100, mean=post_mean_A, sd=post_sd_A),
type="l", col="blue", xlab="mean profit", ylab="posterior density")
lines(x=(400:600)/100, y=dnorm((400:600)/100, mean=post_mean_B, sd=post_sd_B), col="red")
lines(x=(400:600)/100, y=dnorm((400:600)/100, mean=0, sd=100), col="gray")
legend("topright", col=c("blue", "red", "gray"), legend=c("posterior for A", "posterior for B", "prior"), bty="n", lty=1)
plot(x=(400:600)/1000, y=dnorm((400:600)/1000, mean=post_mean_A, sd=post_sd_A),
type="l", col="blue", xlab="mean profit", ylab="posterior density")
lines(x=(400:600)/1000, y=dnorm((400:600)/1000, mean=post_mean_B, sd=post_sd_B), col="red")
lines(x=(400:600)/1000, y=dnorm((400:600)/1000, mean=0, sd=100), col="gray")
legend("topright", col=c("blue", "red", "gray"), legend=c("posterior for A", "posterior for B", "prior"), bty="n", lty=1)
setwd("~/Documents/GitHub/testandroll/howto")
# Optimal test
test_eval_nn(n=n_star, N=N, s=s, mu=mu, sigma=sigma)
# Bigger test
test_eval_nn(n=c(10000, 10000), N=N, s=s, mu=mu, sigma=sigma)
# Smaller test
test_eval_nn(n=c(100, 100), N=N, s=s, mu=mu, sigma=sigma)
mu = c(19.39, 30.06)
sigma = c(20.97, 13.48)
s = c(87.69, 179.36)
test_size_nn(N=100000, mu=mu, sigma=sigma, s=s)
mu = c(20, 30)
sigma = c(10, 10)
s = c(200, 200)
test_size_nn(N=100000, mu=mu, sigma=sigma, s=s)
mu = c(20, 30)
sigma = c(10, 10)
s = c(200, 200)
plot_prior_mean_resp_nn(N=100000, mu=mu, sigma=sigma, s=s)
mu = c(20, 30)
sigma = c(10, 10)
s = c(200, 200)
plot_prior_mean_resp_nn(mu=mu, sigma=sigma, s=s)
mu = c(20, 30)
sigma = c(10, 10)
s = c(200, 200)
plot_prior_mean_resp_nn(mu=mu, sigma=sigma)
test_size_nn(N=100000, mu=mu, sigma=sigma, s=s)
mu = c(20, 30)
sigma = c(10, 20)
s = c(100, 200)
plot_prior_mean_resp_nn(mu=mu, sigma=sigma)
test_size_nn(N=100000, mu=mu, sigma=sigma, s=s)
test_size_nn(N=100000, mu=mu, sigma=sigma, s=s)
setwd("~/Documents/GitHub/testandroll/howto")
library(rstan)
library(dplyr)
options(mc.cores = parallel::detectCores())
setwd("~/Documents/GitHub/testandroll")
source("nn_functions.R")
getwd()
setwd("~/Documents/GitHub/testandroll")
source("nn_functions.R")
source("~/Documents/GitHub/testandroll/nn_functions.R") # some functions I wrote
N <- 100000 # available population
mu <- 0.68  # average conversion rate across previous treatments
sigma <- 0.03 # range of expected conversation rates across previous treatments
s <- mu*(1-mu) # binomial approximation
test_size_nn(N=N, s=s, mu=mu, sigma=sigma) # compute the optimal test size
